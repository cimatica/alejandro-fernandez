{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"UXqJRwEFDHzg","executionInfo":{"status":"ok","timestamp":1734801352794,"user_tz":180,"elapsed":16100,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","source":["#  Perceptron Multicapa"],"metadata":{"id":"X7_Jj6_mu2uh"}},{"cell_type":"markdown","metadata":{"id":"KxVbHzs-aLMg"},"source":["# Datos"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GxqG5a_jaLMg","outputId":"1508f881-90d4-49a0-f02e-67a6a4454b15","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1734801360533,"user_tz":180,"elapsed":3008,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 79.1MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 23.6MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:00<00:00, 90.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 3.68MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 16 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["\n","# Load MNIST dataset\n","# Definimos una secuencia de transformaciones para aplicar a las imágenes del dataset.\n","# En este caso, solo convertimos las imágenes a tensores utilizando `ToTensor()`.\n","# Esto es necesario para que las imágenes estén en un formato compatible con PyTorch.\n","transform = transforms.Compose([\n","    transforms.ToTensor()  # Convierte la imagen de un formato PIL o numpy.ndarray a un tensor.\n","])\n","\n","# Cargamos el dataset MNIST de entrenamiento.\n","# `root='./data'` especifica el directorio donde se descargarán los datos si no están presentes.\n","# `train=True` indica que queremos el conjunto de datos de entrenamiento.\n","# `transform=transform` aplica las transformaciones definidas previamente a cada imagen.\n","# `download=True` descarga los datos si no están disponibles en el directorio especificado.\n","mnist_dataset = datasets.MNIST(\n","    root='./data', train=True, transform=transform, download=True\n",")\n","\n","# Creamos un DataLoader que nos permite cargar los datos en lotes pequeños.\n","# `dataset=mnist_dataset` es el dataset que se cargará.\n","# `batch_size=16` indica que cada lote contendrá 16 imágenes y etiquetas.\n","# `shuffle=True` mezcla los datos aleatoriamente en cada época, mejorando la generalización del modelo.\n","data_loader = DataLoader(\n","    mnist_dataset, batch_size=16, shuffle=True\n",")\n","\n","# Obtenemos un único lote de datos del DataLoader.\n","# `next(iter(data_loader))` convierte el DataLoader en un iterador y toma el primer lote.\n","# El lote contiene `images` (los tensores de las imágenes) y `labels` (las etiquetas correspondientes).\n","images, labels = next(iter(data_loader))\n","\n","\n","# Plot the images in a grid\n","plt.figure(figsize=(10, 10))\n","for i in range(16):\n","    plt.subplot(4, 4, i + 1)\n","    plt.imshow(images[i].squeeze(), cmap='gray')\n","    plt.title(f'Label: {labels[i].item()}')\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"tct5lHD7aLMh"},"source":["# Arquitectura"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"UT7LMM57CqC6","executionInfo":{"status":"ok","timestamp":1734804522981,"user_tz":180,"elapsed":253,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[],"source":["# Definimos el modelo MLP\n","# MLP hereda de nn.Module, lo que permite utilizar las funciones y propiedades de PyTorch\n","# para crear, entrenar y evaluar redes neuronales.\n","class MLP(nn.Module):\n","    def __init__(self):\n","        # Inicializamos la clase base nn.Module\n","        # Esto habilita funciones esenciales como la gestión de capas y forward pass.\n","        super(MLP, self).__init__()\n","        # Capa completamente conectada: de entrada (28x28 píxeles) a 256 neuronas\n","        self.fc1 = nn.Linear(28 * 28, 256)\n","        # Capa oculta: de 100 neuronas a 80 neuronas\n","        self.fc2 = nn.Linear(256, 224)\n","        # Capa oculta: de 80 neuronas a 60 neuronas\n","        self.fc3 = nn.Linear(224, 192)\n","        # Capa oculta: de 60 neuronas a 40 neuronas\n","        self.fc4 = nn.Linear(192, 160)\n","        # Capa de salida: de 40 neuronas a 10 clases (números del 0 al 9)\n","        self.fc5 = nn.Linear(160, 10)\n","        # Función de activación ReLU\n","        self.relu = nn.ReLU()\n","        # Dropout para evitar sobreajuste\n","        self.dropout = nn.Dropout(0.2)\n","\n","    # Definimos cómo pasa la información a través de la red\n","    # Este método es obligatorio en las clases que heredan de nn.Module.\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)  # Aplanamos las imágenes (de 28x28 a 1D)\n","        x = self.relu(self.fc1(x))  # Aplicamos la primera capa y Sigmoid\n","        x = self.dropout(x)         # Aplicamos Dropout\n","        x = self.relu(self.fc2(x))  # Aplicamos la segunda capa y Sigmoid\n","        x = self.dropout(x)         # Aplicamos Dropout\n","        x = self.relu(self.fc3(x))  # Aplicamos la tercera capa y Sigmoid\n","        x = self.dropout(x)         # Aplicamos Dropout\n","        x = self.relu(self.fc4(x))  # Aplicamos la cuarta capa y Sigmoid\n","        x = self.dropout(x)         # Aplicamos Dropout\n","        x = self.fc5(x)             # Aplicamos la capa de salida\n","        return x"]},{"cell_type":"markdown","source":["1. Valores 1ra Ejecucion:<br>\n","Época [1/10], Pérdida: 0.2182\n","Época [2/10], Pérdida: 0.2803\n","Época [3/10], Pérdida: 0.0815\n","Época [4/10], Pérdida: 0.2138\n","Época [5/10], Pérdida: 0.1569\n","Época [6/10], Pérdida: 0.0757\n","Época [7/10], Pérdida: 0.0287\n","Época [8/10], Pérdida: 0.3185\n","Época [9/10], Pérdida: 0.0172\n","Época [10/10], Pérdida: 0.0963<br>\n","Accuracy en el conjunto de prueba: 97.67% <br>\n","2. 1er cambio en Arquitectura: <br>\n","*  Se modifica numero de neuronas:\n","* - Capa completamente conectada: de entrada (28x28 píxeles) a 100 neuronas\n","* - Capa oculta: de 100 neuronas a 80 neuronas\n","* - Capa oculta: de 80 neuronas a 60 neuronas\n","* - Capa oculta: de 60 neuronas a 40 neuronas\n","* - Capa de salida: de 40 neuronas a 10 clases (números del 0 al 9)\n","*  Se agregan 2 capas ocultas.\n","* Se modifica la funcion de activacion (de ReLU a Sigmoid)\n","* Resultado del Entrenamiento (1er cambio en Arquitectura):\n","* Valores 2da Ejecucion: <br>\n","Época [1/10], Pérdida: 0.9339\n","Época [2/10], Pérdida: 0.4045\n","Época [3/10], Pérdida: 0.5679\n","Época [4/10], Pérdida: 0.2500\n","Época [5/10], Pérdida: 0.2769\n","Época [6/10], Pérdida: 0.0875\n","Época [7/10], Pérdida: 0.3500\n","Época [8/10], Pérdida: 0.3871\n","Época [9/10], Pérdida: 0.0709\n","Época [10/10], Pérdida: 0.2696<br>\n","Accuracy en el conjunto de prueba: 95.66% <br>\n","* Conclusion: variaciones en los valores resultante de las epocas, teniendo un mayor valor de perdida. Disminucion en el porcentaje del Accuracy quedando en un: 95.66%.  Los cambios realizados no reflejan un mejor resultado respecto al codigo original. <br>\n","2. 2do cambio en Arquitectura: <br>\n","* Se modifica la funcion de activacion de Sigmoid a ReLU, para analizar si la la variacion en la Perdida y Accuracy, esta dada por la funcion de activacion o los cambios en el numeros de cpas y celulas.<br>\n","* Resultado del Entrenamiento (2do cambio en Arquitectura): <br>\n","Época [1/10], Pérdida: 0.2348\n","Época [2/10], Pérdida: 0.5427\n","Época [3/10], Pérdida: 0.0350\n","Época [4/10], Pérdida: 0.1471\n","Época [5/10], Pérdida: 0.1517\n","Época [6/10], Pérdida: 0.1792\n","Época [7/10], Pérdida: 0.4189\n","Época [8/10], Pérdida: 0.1986\n","Época [9/10], Pérdida: 0.1589\n","Época [10/10], Pérdida: 0.1025 <br>\n","Accuracy en el conjunto de prueba: 96.41% <br>\n","* Conclusion: Con el cambio de la funcion de activacion (ReLu) se presenta variaciones en los valores resultante de las epocas, teniendo un menor valor de perdida. Aumento en el porcentaje del Accuracy quedando a un: 96.41%. Sin embargo no mejora el porcentaje del Accuracy respecto al codigo original. <br>\n","3. 3er cambio en Arquitectura: <br>\n","* Se modifica numero de neuronas pasando de 100 de 256\n","* - Capa completamente conectada: de entrada (28x28 píxeles) a 256 neuronas\n","* - Capa oculta: de 256 neuronas a 224 neuronas\n","* - Capa oculta: de 224 neuronas a 192 neuronas\n","* - Capa oculta: de 192 neuronas a 160 neuronas\n","* - Capa de salida: de 160 neuronas a 10 clases (números del 0 al 9) <br>\n","* Resultado del Entrenamiento (3er cambio en Arquitectura): <br>\n","Época [1/10], Pérdida: 0.1484\n","Época [2/10], Pérdida: 0.1461\n","Época [3/10], Pérdida: 0.2861\n","Época [4/10], Pérdida: 0.1349\n","Época [5/10], Pérdida: 0.1573\n","Época [6/10], Pérdida: 0.1962\n","Época [7/10], Pérdida: 0.4015\n","Época [8/10], Pérdida: 0.0255\n","Época [9/10], Pérdida: 0.0207\n","Época [10/10], Pérdida: 0.1220 <br>\n","Accuracy en el conjunto de prueba: 97.42% <br>\n","* Conclusion: Con el cambio en el numero de celulas se presenta una mejora en el porcentaje del Accuracy a un 97.42%.  Sin embargo no mejora el porcentaje del Accuracy respecto al codigo original.  A mayor numero de celulas, es mejor es el resultado<br>\n","3. Se mantienen los ultimos cambios realizado en la Arquitectura para realizar cambios en el Entrenamiento."],"metadata":{"id":"udoRG_Q2AJme"}},{"cell_type":"markdown","metadata":{"id":"mgGJQxDyaLMi"},"source":["# Entrenamiento"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"oV3ojjtpaLMi","outputId":"c8349e2e-dedc-40ea-9aa4-a2e79af9cf01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734808740831,"user_tz":180,"elapsed":374544,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Época [1/20], Pérdida: 0.2822\n","Época [2/20], Pérdida: 0.1298\n","Época [3/20], Pérdida: 0.1666\n","Época [4/20], Pérdida: 0.0843\n","Época [5/20], Pérdida: 0.0842\n","Época [6/20], Pérdida: 0.1294\n","Época [7/20], Pérdida: 0.2234\n","Época [8/20], Pérdida: 0.1434\n","Época [9/20], Pérdida: 0.1544\n","Época [10/20], Pérdida: 0.0672\n","Época [11/20], Pérdida: 0.0805\n","Época [12/20], Pérdida: 0.1092\n","Época [13/20], Pérdida: 0.1195\n","Época [14/20], Pérdida: 0.1262\n","Época [15/20], Pérdida: 0.0515\n","Época [16/20], Pérdida: 0.0495\n","Época [17/20], Pérdida: 0.0292\n","Época [18/20], Pérdida: 0.2243\n","Época [19/20], Pérdida: 0.1205\n","Época [20/20], Pérdida: 0.0545\n"]}],"source":["# Hiperparámetros\n","batch_size = 128      # Tamaño de lote\n","learning_rate = 0.001 # Tasa de aprendizaje\n","epochs = 20           # Número de épocas de entrenamiento\n","\n","# Preprocesamiento y carga de datos de MNIST\n","transform = transforms.Compose([\n","    transforms.ToTensor(),                 # Convertimos imágenes a tensores\n","    transforms.Normalize((0.5,), (0.5,))  # Normalizamos a media 0 y varianza 1\n","])\n","train_dataset = datasets.MNIST(\n","    root='./data', train=True, transform=transform, download=True)  # Dataset de entrenamiento\n","test_dataset = datasets.MNIST(\n","    root='./data', train=False, transform=transform, download=True)  # Dataset de prueba\n","train_loader = DataLoader(\n","    dataset=train_dataset, batch_size=batch_size, shuffle=True)  # Dataloader para entrenamiento\n","test_loader = DataLoader(\n","    dataset=test_dataset, batch_size=batch_size, shuffle=False)  # Dataloader para prueba\n","\n","# Definimos el modelo, la función de pérdida y el optimizador\n","model = MLP()                             # Creamos una instancia del modelo MLP\n","criterion = nn.CrossEntropyLoss()         # Función de pérdida para clasificación\n","#optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Optimizador Adam\n","optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)  # Optimizador RMSprop\n","\n","# Bucle de entrenamiento\n","for epoch in range(epochs):\n","    model.train()  # Ponemos el modelo en modo entrenamiento\n","    for images, labels in train_loader:  # Iteramos sobre lotes de datos\n","        optimizer.zero_grad()            # Reiniciamos los gradientes\n","        outputs = model(images)          # Hacemos una predicción con el modelo\n","        loss = criterion(outputs, labels)  # Calculamos la pérdida\n","        loss.backward()                  # Propagamos los gradientes\n","        optimizer.step()                 # Actualizamos los pesos del modelo\n","\n","    # Mostramos la pérdida al final de cada época\n","    print(f\"Época [{epoch+1}/{epochs}], Pérdida: {loss.item():.4f}\")\n"]},{"cell_type":"markdown","source":["1. 1er cambio en Entrenamiento: <br>\n","*  Numero de Epocas de 10 a 20\n","* Resultado del Entrenamiento (1er cambio Entrenamiento):\n","* Valores Ejecucion: <br>\n","Época [1/20], Pérdida: 0.6885\n","Época [2/20], Pérdida: 0.0973\n","Época [3/20], Pérdida: 0.1005\n","Época [4/20], Pérdida: 0.0435\n","Época [5/20], Pérdida: 0.2100\n","Época [6/20], Pérdida: 0.2297\n","Época [7/20], Pérdida: 0.0291\n","Época [8/20], Pérdida: 0.0551\n","Época [9/20], Pérdida: 0.0332\n","Época [10/20], Pérdida: 0.1258\n","Época [11/20], Pérdida: 0.2096\n","Época [12/20], Pérdida: 0.0533\n","Época [13/20], Pérdida: 0.0245\n","Época [14/20], Pérdida: 0.0320\n","Época [15/20], Pérdida: 0.0678\n","Época [16/20], Pérdida: 0.1008\n","Época [17/20], Pérdida: 0.1201\n","Época [18/20], Pérdida: 0.1111\n","Época [19/20], Pérdida: 0.0247\n","Época [20/20], Pérdida: 0.1967 <br>\n","Accuracy en el conjunto de prueba: 97.75% <br>\n","* Conclusion: variaciones en los valores resultante de las epocas, teniendo un mayor valor de perdida. Aumento en el porcentaje del Accuracy quedando en un: 97.75%.  Los cambios realizados reflejan un mejor resultado en el Accuracy respecto al codigo original. <br>\n","2. 2do cambio en Entrenamiento: <br>\n","*  Se modifica tamaño del lote (batch size) de 64 a 128\n","*  El Learning Rate de 0.001 a 0.005 <br>\n","* Resultado del Entrenamiento (2do  cambio Entrenamiento):\n","* Valores Ejecucion: <br>\n","Época [1/20], Pérdida: 0.4876\n","Época [2/20], Pérdida: 0.2111\n","Época [3/20], Pérdida: 0.2688\n","Época [4/20], Pérdida: 0.5059\n","Época [5/20], Pérdida: 0.3583\n","Época [6/20], Pérdida: 0.2056\n","Época [7/20], Pérdida: 0.2553\n","Época [8/20], Pérdida: 0.2460\n","Época [9/20], Pérdida: 0.3319\n","Época [10/20], Pérdida: 0.3720\n","Época [11/20], Pérdida: 0.3676\n","Época [12/20], Pérdida: 0.2316\n","Época [13/20], Pérdida: 0.5375\n","Época [14/20], Pérdida: 0.2786\n","Época [15/20], Pérdida: 0.4118\n","Época [16/20], Pérdida: 0.3062\n","Época [17/20], Pérdida: 0.4930\n","Época [18/20], Pérdida: 0.2567\n","Época [19/20], Pérdida: 0.2385\n","Época [20/20], Pérdida: 0.3374 <br>\n","Accuracy en el conjunto de prueba: 94.71% <br>\n","* Conclusion: variaciones en los valores resultante de las epocas, teniendo un mayor valor de perdida. Disminuyendo en el porcentaje del Accuracy quedando en un: 94.71%.  Los cambios realizados en los hiperparametros batch size y Learning Rate reflejan un peor resultado en el Accuracy respecto al ccambio anterior. <br>\n","2. 3er cambio en Entrenamiento: <br>\n","*  Se modifica el Learning Rate de 0.005 a 0.001 <br>\n","* Resultado del Entrenamiento (3er cambio Entrenamiento):\n","* Valores Ejecucion: <br>\n","Época [1/20], Pérdida: 0.2679\n","Época [2/20], Pérdida: 0.2300\n","Época [3/20], Pérdida: 0.1016\n","Época [4/20], Pérdida: 0.1419\n","Época [5/20], Pérdida: 0.2026\n","Época [6/20], Pérdida: 0.0863\n","Época [7/20], Pérdida: 0.0724\n","Época [8/20], Pérdida: 0.1074\n","Época [9/20], Pérdida: 0.0410\n","Época [10/20], Pérdida: 0.1389\n","Época [11/20], Pérdida: 0.1260\n","Época [12/20], Pérdida: 0.0644\n","Época [13/20], Pérdida: 0.1502\n","Época [14/20], Pérdida: 0.1925\n","Época [15/20], Pérdida: 0.0732\n","Época [16/20], Pérdida: 0.0582\n","Época [17/20], Pérdida: 0.0706\n","Época [18/20], Pérdida: 0.0260\n","Época [19/20], Pérdida: 0.1061\n","Época [20/20], Pérdida: 0.0857 <br>\n","Accuracy en el conjunto de prueba: 97.65% <br>\n","* Conclusion: variaciones en los valores resultante de las epocas, teniendo un menor valor de perdida. Aumentando el porcentaje del Accuracy quedando en un: 97.65%.  Los cambios realizados en los hiperparametros batch size y Learning Rate reflejan un peor resultado en el Accuracy respecto al ccambio anterior.\n","El cambio en la tasa de aprendizaje (Learning Rate) a 000.1 relfeja una mejora importante. Si se compara con el cambio anterior, el cambio en el hiperparametro batch size a 128 afecta negativamente en el resultado.<br>\n","3. 4to cambio en Entrenamiento: <br>\n","* Del optimizador Adam al RMSprop\n","* Resultado del Entrenamiento (4to cambio Entrenamiento):\n","* Valores Ejecucion: <br>\n","Época [1/20], Pérdida: 0.2822\n","Época [2/20], Pérdida: 0.1298\n","Época [3/20], Pérdida: 0.1666\n","Época [4/20], Pérdida: 0.0843\n","Época [5/20], Pérdida: 0.0842\n","Época [6/20], Pérdida: 0.1294\n","Época [7/20], Pérdida: 0.2234\n","Época [8/20], Pérdida: 0.1434\n","Época [9/20], Pérdida: 0.1544\n","Época [10/20], Pérdida: 0.0672\n","Época [11/20], Pérdida: 0.0805\n","Época [12/20], Pérdida: 0.1092\n","Época [13/20], Pérdida: 0.1195\n","Época [14/20], Pérdida: 0.1262\n","Época [15/20], Pérdida: 0.0515\n","Época [16/20], Pérdida: 0.0495\n","Época [17/20], Pérdida: 0.0292\n","Época [18/20], Pérdida: 0.2243\n","Época [19/20], Pérdida: 0.1205\n","Época [20/20], Pérdida: 0.0545 <br>\n","Accuracy en el conjunto de prueba: 97.37% <br>\n","Conclusion: variaciones en los valores resultante de las epocas, teniendo un menor valor de perdida. Disminuyendo levemente el porcentaje del Accuracy quedando en un: 97.37%.  El optimizador Adam presenta un mejor resultado."],"metadata":{"id":"fA4wcluCAbtc"}},{"cell_type":"markdown","metadata":{"id":"4b0ozgcraLMi"},"source":["# Evaluación del modelo"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"tTyHa34XCrxN","outputId":"8d792ea4-a73a-4497-fc19-304ba9598486","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734811554940,"user_tz":180,"elapsed":2833,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy en el conjunto de prueba: 97.37%\n"]}],"source":["model.eval()  # Ponemos el modelo en modo evaluación (desactiva Dropout)\n","correct = 0\n","total = 0\n","with torch.no_grad():  # Desactivamos el cálculo de gradientes para evaluación\n","    for images, labels in test_loader:  # Iteramos sobre los datos de prueba\n","        outputs = model(images)         # Hacemos predicciones\n","        _, predicted = torch.max(outputs.data, 1)  # Obtenemos la clase con mayor probabilidad\n","        total += labels.size(0)         # Total de muestras evaluadas\n","        correct += (predicted == labels).sum().item()  # Contamos las predicciones correctas\n","\n","# Calculamos y mostramos la precisión del modelo\n","accuracy = 100 * correct / total\n","print(f\"Accuracy en el conjunto de prueba: {accuracy:.2f}%\")"]},{"cell_type":"markdown","source":["\n","# Redes convolucionales\n","\n"],"metadata":{"id":"u3OX1PFDuptl"}},{"cell_type":"code","execution_count":48,"metadata":{"id":"ZqmhpmB3aLMj","executionInfo":{"status":"ok","timestamp":1734821240586,"user_tz":180,"elapsed":248,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[],"source":["# Verificar si hay una GPU disponible, de lo contrario usar la CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Preprocesamiento: Definir transformaciones para los datos\n","transform = transforms.Compose([\n","    transforms.ToTensor(),                # Convertir imágenes a tensores\n","    transforms.Normalize((0.5,), (0.5,))  # Normalizar los valores a un rango de [-1, 1]\n","])\n","\n","# Cargar el conjunto de datos MNIST\n","train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)  # Datos de entrenamiento\n","test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)  # Datos de prueba\n","\n","# Crear DataLoaders para manejar los datos de forma eficiente\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)   # Loader para entrenamiento (batch de 128, mezclado)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)    # Loader para prueba (batch de 128, sin mezclar)\n","\n","class CNN(nn.Module):\n","    def __init__(self, verbose=False, filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=128):\n","        super(CNN, self).__init__()\n","        self.verbose = verbose\n","        self.filters_l1 = filters_l1\n","        self.filters_l2 = filters_l2\n","        self.dropout_rate = dropout\n","        self.final_layer_size = final_layer_size\n","\n","        # Primera capa convolucional\n","        self.conv1 = nn.Conv2d(1, self.filters_l1, kernel_size=9, stride=1, padding=0)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Segunda capa convolucional\n","        self.conv2 = nn.Conv2d(self.filters_l1, self.filters_l2, kernel_size=3, stride=1, padding=1)\n","\n","        # Calcular automáticamente las dimensiones de la capa lineal (fc1)\n","        self.fc1_input_size = self._calculate_fc1_input_size()\n","\n","        # Primera capa completamente conectada\n","        self.fc1 = nn.Linear(self.fc1_input_size, self.final_layer_size)\n","        self.dropout = nn.Dropout(self.dropout_rate)\n","        self.fc2 = nn.Linear(self.final_layer_size, 10)  # Capa de salida para 10 clases (MNIST)\n","\n","    def _calculate_fc1_input_size(self):\n","        \"\"\"\n","        Calcula automáticamente el tamaño de la entrada para la primera capa completamente conectada (fc1).\n","        Simula una pasada con una imagen de prueba de tamaño (1, 28, 28).\n","        \"\"\"\n","        with torch.no_grad():  # Desactiva gradientes\n","            x = torch.randn(1, 1, 28, 28)  # Tensor ficticio de entrada con tamaño MNIST (batch_size=1)\n","            x = self.pool(torch.relu(self.conv1(x)))  # Aplicar Conv1 -> Pool\n","            x = self.pool(torch.relu(self.conv2(x)))  # Aplicar Conv2 -> Pool\n","            fc1_input_size = x.numel()  # Calcular número total de elementos\n","        return fc1_input_size\n","\n","    def forward(self, x):\n","        if self.verbose:\n","            print(f\"Entrada: {x.shape}\")  # Imprime la dimensión de la entrada\n","\n","        # Primera capa convolucional, ReLU y MaxPooling\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        if self.verbose:\n","            print(f\"Después de Conv1 y MaxPooling: {x.shape}\")  # Dimensión después de Conv1 y Pool\n","\n","        # Segunda capa convolucional, ReLU y MaxPooling\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        if self.verbose:\n","            print(f\"Después de Conv2 y MaxPooling: {x.shape}\")  # Dimensión después de Conv2 y Pool\n","\n","        # Aplanar las características 2D a 1D\n","        x = x.view(-1, self.fc1_input_size)\n","        if self.verbose:\n","            print(f\"Después de Aplanamiento: {x.shape}\")  # Dimensión después de Flatten\n","\n","        # Primera capa completamente conectada\n","        x = torch.relu(self.fc1(x))\n","        if self.verbose:\n","            print(f\"Después de Fully Connected (fc1): {x.shape}\")  # Dimensión después de fc1\n","\n","        # Aplicar Dropout\n","        x = self.dropout(x)\n","        if self.verbose:\n","            print(f\"Después de Dropout: {x.shape}\")  # Dimensión después de Dropout\n","\n","        # Capa de salida\n","        x = self.fc2(x)\n","        if self.verbose:\n","            print(f\"Después de Fully Connected (fc2): {x.shape}\")  # Dimensión después de fc2 (salida final)\n","\n","        return x\n","\n"]},{"cell_type":"markdown","source":["* Valores Ejecucion inicial: <br>\n","Epoch [1/10], Loss: 0.3973, Test Accuracy: 0.9750\n","Epoch [2/10], Loss: 0.0970, Test Accuracy: 0.9838\n","Epoch [3/10], Loss: 0.0680, Test Accuracy: 0.9852\n","Epoch [4/10], Loss: 0.0557, Test Accuracy: 0.9858\n","Epoch [5/10], Loss: 0.0472, Test Accuracy: 0.9897\n","Epoch [6/10], Loss: 0.0411, Test Accuracy: 0.9902\n","Epoch [7/10], Loss: 0.0365, Test Accuracy: 0.9905\n","Epoch [8/10], Loss: 0.0313, Test Accuracy: 0.9903\n","Epoch [9/10], Loss: 0.0298, Test Accuracy: 0.9910\n","Epoch [10/10], Loss: 0.0254, Test Accuracy: 0.9909 <br>\n","Final Test Accuracy: 0.9909 <br>\n","\n","1. 1er cambio en Parametros:\n","* Original: filters_l1=8, filters_l2=32, dropout=0.2\n","* Cambio: filters_l1=16, filters_l2=64, dropout=0.5\n","* Resultado (1er cambio Parametros):\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3434, Test Accuracy: 0.9753\n","Epoch [2/10], Loss: 0.0931, Test Accuracy: 0.9834\n","Epoch [3/10], Loss: 0.0674, Test Accuracy: 0.9864\n","Epoch [4/10], Loss: 0.0520, Test Accuracy: 0.9871\n","Epoch [5/10], Loss: 0.0450, Test Accuracy: 0.9901\n","Epoch [6/10], Loss: 0.0371, Test Accuracy: 0.9897\n","Epoch [7/10], Loss: 0.0314, Test Accuracy: 0.9894\n","Epoch [8/10], Loss: 0.0290, Test Accuracy: 0.9897\n","Epoch [9/10], Loss: 0.0245, Test Accuracy: 0.9909\n","Epoch [10/10], Loss: 0.0212, Test Accuracy: 0.9906<br>\n","Final Test Accuracy: 0.9906 <br>\n","* Conclusion: Con los cambios realizados hay una leve disminucion en el final test Accuracy de 0.9909 a 0.9906\n","\n","2. 2do cambio en Parametros:\n","* dropout=0.5 a dropout=0.2\n","* Resultado (2do cambio Parametros):\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3626, Test Accuracy: 0.9749\n","Epoch [2/10], Loss: 0.0876, Test Accuracy: 0.9840\n","Epoch [3/10], Loss: 0.0611, Test Accuracy: 0.9871\n","Epoch [4/10], Loss: 0.0486, Test Accuracy: 0.9873\n","Epoch [5/10], Loss: 0.0404, Test Accuracy: 0.9898\n","Epoch [6/10], Loss: 0.0349, Test Accuracy: 0.9892\n","Epoch [7/10], Loss: 0.0304, Test Accuracy: 0.9906\n","Epoch [8/10], Loss: 0.0267, Test Accuracy: 0.9891\n","Epoch [9/10], Loss: 0.0231, Test Accuracy: 0.9902\n","Epoch [10/10], Loss: 0.0195, Test Accuracy: 0.9906\n","Final Test Accuracy: 0.9906 <br>\n","* Conclusion: Al cambiar el valor del dropout a 0.2 el Final Test Accuracy queda en un 0.9906 (mismo resultado que en la ejeucion inicial). Los cambios en el resultado del test, estan dado por las modificacion en el dropout y no por hechos en los filtros.\n","\n","3. 3er cambio en Parametros:\n","* Cambio en los valores de los filtro para analizar comportamiento\n","* Cambio: filters_l1=64, filters_l2=128\n","* Resultado (3er cambio Parametro):\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3521, Test Accuracy: 0.9738\n","Epoch [2/10], Loss: 0.0933, Test Accuracy: 0.9824\n","Epoch [3/10], Loss: 0.0699, Test Accuracy: 0.9880\n","Epoch [4/10], Loss: 0.0559, Test Accuracy: 0.9886\n","Epoch [5/10], Loss: 0.0458, Test Accuracy: 0.9881\n","Epoch [6/10], Loss: 0.0404, Test Accuracy: 0.9889\n","Epoch [7/10], Loss: 0.0359, Test Accuracy: 0.9899\n","Epoch [8/10], Loss: 0.0314, Test Accuracy: 0.9900\n","Epoch [9/10], Loss: 0.0261, Test Accuracy: 0.9890\n","Epoch [10/10], Loss: 0.0253, Test Accuracy: 0.9898\n","Final Test Accuracy: 0.9898 <br>\n","* Conclusion: No refleja una mejora en los resultados del Final Test Accuracy al cambiar los valores en los filtros.\n","\n","4. 4er cambio en Parametros:\n","* Se vuelven a los valores originales de los filtros y drop out.\n","* Se modifica el valor de la capa lineal a final_layer_size=256\n","* Resultado (4to cambio Parametros):\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3504, Test Accuracy: 0.9729\n","Epoch [2/10], Loss: 0.0865, Test Accuracy: 0.9848\n","Epoch [3/10], Loss: 0.0632, Test Accuracy: 0.9850\n","Epoch [4/10], Loss: 0.0500, Test Accuracy: 0.9880\n","Epoch [5/10], Loss: 0.0412, Test Accuracy: 0.9885\n","Epoch [6/10], Loss: 0.0344, Test Accuracy: 0.9880\n","Epoch [7/10], Loss: 0.0293, Test Accuracy: 0.9884\n","Epoch [8/10], Loss: 0.0266, Test Accuracy: 0.9880\n","Epoch [9/10], Loss: 0.0226, Test Accuracy: 0.9907\n","Epoch [10/10], Loss: 0.0224, Test Accuracy: 0.9906 <br>\n","Final Test Accuracy: 0.9906 <br>\n","* Conclusion:El cambio del valor en la capa lineal refleja una mejora en los resultados del Final Test Accuracy quedando en un 0.9906, mismo resultado que se presento con el 1er cambio.\n","\n","5. 5to cambio en Parametro:\n","* Cambio en los filters_l1=64, filters_l2=128, se mantiene ultimo cambio de la capa final a 256.\n","* Resultado (5to cambio Parametro):\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3454, Test Accuracy: 0.9760\n","Epoch [2/10], Loss: 0.0929, Test Accuracy: 0.9832\n","Epoch [3/10], Loss: 0.0659, Test Accuracy: 0.9853\n","Epoch [4/10], Loss: 0.0532, Test Accuracy: 0.9866\n","Epoch [5/10], Loss: 0.0462, Test Accuracy: 0.9876\n","Epoch [6/10], Loss: 0.0391, Test Accuracy: 0.9893\n","Epoch [7/10], Loss: 0.0356, Test Accuracy: 0.9893\n","Epoch [8/10], Loss: 0.0311, Test Accuracy: 0.9890\n","Epoch [9/10], Loss: 0.0273, Test Accuracy: 0.9897\n","Epoch [10/10], Loss: 0.0222, Test Accuracy: 0.9899 <br>\n","Final Test Accuracy: 0.9899 <br>\n","* Conclusion: El cambio en los valores de los filtros no presenta una mejora en el resultado del Final Test Accuracy quedando en un 0.9899. <br>\n","\n","6. 6to cambio en Parametro:\n","* filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=64\n","* Resultado (6to cambio Parametro):\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3130, Test Accuracy: 0.9763\n","Epoch [2/10], Loss: 0.0811, Test Accuracy: 0.9832\n","Epoch [3/10], Loss: 0.0576, Test Accuracy: 0.9872\n","Epoch [4/10], Loss: 0.0448, Test Accuracy: 0.9889\n","Epoch [5/10], Loss: 0.0379, Test Accuracy: 0.9883\n","Epoch [6/10], Loss: 0.0311, Test Accuracy: 0.9884\n","Epoch [7/10], Loss: 0.0254, Test Accuracy: 0.9896\n","Epoch [8/10], Loss: 0.0235, Test Accuracy: 0.9915\n","Epoch [9/10], Loss: 0.0194, Test Accuracy: 0.9900\n","Epoch [10/10], Loss: 0.0176, Test Accuracy: 0.9905 <br>\n","Final Test Accuracy: 0.9905 <br>\n","* Conclusion: El cambio en los valores de los filtros presenta una mejora en el resultado del Final Test Accuracy quedando en un 0.9905. El cambio del valor en la capa lineal a 64 y manteniendo los valores originales en los filtros refleja obtiene un resultado muy cercano al valor de los parametros del  codigo original. <br>\n","\n","7. Se vuelven a los valores originales de los parametros de entrada:\n","* filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=128\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3499, Test Accuracy: 0.9724\n","Epoch [2/10], Loss: 0.0908, Test Accuracy: 0.9818\n","Epoch [3/10], Loss: 0.0644, Test Accuracy: 0.9859\n","Epoch [4/10], Loss: 0.0538, Test Accuracy: 0.9877\n","Epoch [5/10], Loss: 0.0455, Test Accuracy: 0.9869\n","Epoch [6/10], Loss: 0.0370, Test Accuracy: 0.9881\n","Epoch [7/10], Loss: 0.0345, Test Accuracy: 0.9897\n","Epoch [8/10], Loss: 0.0293, Test Accuracy: 0.9911\n","Epoch [9/10], Loss: 0.0266, Test Accuracy: 0.9885\n","Epoch [10/10], Loss: 0.0232, Test Accuracy: 0.9904 <br>\n","Final Test Accuracy: 0.9904<br>\n","Conclusion: Al volver a los valores originales y realizar la ejecucion, no se presenta el mismo resultado inicial: <br>\n","* Final Test Accuracy: 0.9909 - Inicial\n","* Final Test Accuracy: 0.9904 - Final <br>\n","\n","8. Cambio en la Primera capa convolucional: en kernel y padding\n","* original: self.conv1 = nn.Conv2d(1, self.filters_l1, kernel_size=3, stride=1, padding=1)\n","* nuevo: self.conv1 = nn.Conv2d(1, self.filters_l1, kernel_size=9, stride=1, padding=0)\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.2863, Test Accuracy: 0.9771\n","Epoch [2/10], Loss: 0.0839, Test Accuracy: 0.9835\n","Epoch [3/10], Loss: 0.0631, Test Accuracy: 0.9873\n","Epoch [4/10], Loss: 0.0490, Test Accuracy: 0.9878\n","Epoch [5/10], Loss: 0.0427, Test Accuracy: 0.9888\n","Epoch [6/10], Loss: 0.0355, Test Accuracy: 0.9896\n","Epoch [7/10], Loss: 0.0306, Test Accuracy: 0.9913\n","Epoch [8/10], Loss: 0.0277, Test Accuracy: 0.9915\n","Epoch [9/10], Loss: 0.0232, Test Accuracy: 0.9924\n","Epoch [10/10], Loss: 0.0212, Test Accuracy: 0.9912 <br>\n","Final Test Accuracy: 0.9912 <br>\n","Conclusion: El cambio a la primera capa convolucional presenta mejoras en el Final Test Accuracy: 0.9912, superando el del resultado del codigo inicial (0.9909)<br>\n","\n","9. Cambio en la Segunda capa convolucional: en kernel y padding\n","* original: self.conv2 = nn.Conv2d(self.filters_l1, self.filters_l2, kernel_size=3, stride=1, padding=1)\n","* nuevo: self.conv2 = nn.Conv2d(self.filters_l1, self.filters_l2, kernel_size=9, stride=1, padding=0)\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.3594, Test Accuracy: 0.9710\n","Epoch [2/10], Loss: 0.0980, Test Accuracy: 0.9783\n","Epoch [3/10], Loss: 0.0712, Test Accuracy: 0.9869\n","Epoch [4/10], Loss: 0.0587, Test Accuracy: 0.9869\n","Epoch [5/10], Loss: 0.0487, Test Accuracy: 0.9866\n","Epoch [6/10], Loss: 0.0444, Test Accuracy: 0.9874\n","Epoch [7/10], Loss: 0.0401, Test Accuracy: 0.9879\n","Epoch [8/10], Loss: 0.0378, Test Accuracy: 0.9873\n","Epoch [9/10], Loss: 0.0334, Test Accuracy: 0.9874\n","Epoch [10/10], Loss: 0.0296, Test Accuracy: 0.9876 <br>\n","Final Test Accuracy: 0.9876 <br>\n","Conclusion: El cambio no presenta mejora, disminuyendo el Final Test Accuracy a un 0.9876 <br>\n","\n","10. 1er cambio en optimizador: Se deshacen los cambios hechos en la segunda capa convolusional.  Se modifica del optimizador Adam al RMSprop.\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.1804, Test Accuracy: 0.9811\n","Epoch [2/10], Loss: 0.0653, Test Accuracy: 0.9881\n","Epoch [3/10], Loss: 0.0475, Test Accuracy: 0.9896\n","Epoch [4/10], Loss: 0.0384, Test Accuracy: 0.9892\n","Epoch [5/10], Loss: 0.0328, Test Accuracy: 0.9905\n","Epoch [6/10], Loss: 0.0268, Test Accuracy: 0.9920\n","Epoch [7/10], Loss: 0.0228, Test Accuracy: 0.9916\n","Epoch [8/10], Loss: 0.0195, Test Accuracy: 0.9927\n","Epoch [9/10], Loss: 0.0173, Test Accuracy: 0.9924\n","Epoch [10/10], Loss: 0.0157, Test Accuracy: 0.9926 <br>\n","Final Test Accuracy: 0.9926 <br>\n","Conclusion: El cambio en el optimizador presenta mejora en Final Test Accuracy a un 0.9926.  Para esta prueba el optimziador RMSprop tiene un mejor resultado <br>\n","\n","11. 2do cambio en optimizador: Se modifica la tasa de aprendizaje del optimizador RMSprop al 0.005 para comparar comportamiento.\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.2573, Test Accuracy: 0.9752\n","Epoch [2/10], Loss: 0.0749, Test Accuracy: 0.9850\n","Epoch [3/10], Loss: 0.0609, Test Accuracy: 0.9802\n","Epoch [4/10], Loss: 0.0532, Test Accuracy: 0.9847\n","Epoch [5/10], Loss: 0.0466, Test Accuracy: 0.9759\n","Epoch [6/10], Loss: 0.0438, Test Accuracy: 0.9897\n","Epoch [7/10], Loss: 0.0411, Test Accuracy: 0.9868\n","Epoch [8/10], Loss: 0.0406, Test Accuracy: 0.9860\n","Epoch [9/10], Loss: 0.0379, Test Accuracy: 0.9821\n","Epoch [10/10], Loss: 0.0358, Test Accuracy: 0.9872 <br>\n","Final Test Accuracy: 0.9872<br>\n","Conclusion: El cambio en la tasa de aprendizaje en el optimizador RMSprop no presenta mejora en Final Test Accuracy quedando en un 0.9872 respecto al valor anterior de un 0.9926.\n","\n","12. Finalmente se deja el optimizador RMSprop, con una tasa de aprendizaje en 0.001. Ya que presenta el mejor resultado en el Final Test Accuracy: 0.9926.\n","* Valores Ejecucion: <br>\n","Epoch [1/10], Loss: 0.1986, Test Accuracy: 0.9821\n","Epoch [2/10], Loss: 0.0704, Test Accuracy: 0.9862\n","Epoch [3/10], Loss: 0.0505, Test Accuracy: 0.9849\n","Epoch [4/10], Loss: 0.0397, Test Accuracy: 0.9898\n","Epoch [5/10], Loss: 0.0318, Test Accuracy: 0.9903\n","Epoch [6/10], Loss: 0.0275, Test Accuracy: 0.9896\n","Epoch [7/10], Loss: 0.0233, Test Accuracy: 0.9923\n","Epoch [8/10], Loss: 0.0191, Test Accuracy: 0.9928\n","Epoch [9/10], Loss: 0.0178, Test Accuracy: 0.9912\n","Epoch [10/10], Loss: 0.0162, Test Accuracy: 0.9926<br>\n","Final Test Accuracy: 0.9926"],"metadata":{"id":"H5HAPP86DqcO"}},{"cell_type":"code","execution_count":52,"metadata":{"id":"-nsFt9vYaLMj","outputId":"39b16c74-b783-45b5-e782-3a27efabf312","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734823477537,"user_tz":180,"elapsed":325338,"user":{"displayName":"Alejandro Fernández Gajardo","userId":"09044838795464689773"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.1986, Test Accuracy: 0.9821\n","Epoch [2/10], Loss: 0.0704, Test Accuracy: 0.9862\n","Epoch [3/10], Loss: 0.0505, Test Accuracy: 0.9849\n","Epoch [4/10], Loss: 0.0397, Test Accuracy: 0.9898\n","Epoch [5/10], Loss: 0.0318, Test Accuracy: 0.9903\n","Epoch [6/10], Loss: 0.0275, Test Accuracy: 0.9896\n","Epoch [7/10], Loss: 0.0233, Test Accuracy: 0.9923\n","Epoch [8/10], Loss: 0.0191, Test Accuracy: 0.9928\n","Epoch [9/10], Loss: 0.0178, Test Accuracy: 0.9912\n","Epoch [10/10], Loss: 0.0162, Test Accuracy: 0.9926\n","Final Test Accuracy: 0.9926\n"]}],"source":["# Inicializar el modelo, la función de pérdida y el optimizador\n","model = CNN(verbose=False, filters_l1=8, filters_l2=32, dropout=0.2, final_layer_size=128).to(device)                             # Mover el modelo a la GPU/CPU\n","criterion = nn.CrossEntropyLoss()                    # Función de pérdida para clasificación multiclase\n","optimizer = optim.RMSprop(model.parameters(), lr=0.001) # Optimizador Adam con tasa de aprendizaje 0.001\n","\n","# Definir la función de entrenamiento\n","def train(model, loader, criterion, optimizer, device):\n","    model.train()  # Establecer el modelo en modo de entrenamiento\n","    running_loss = 0.0\n","    for images, labels in loader:  # Iterar sobre los lotes de datos\n","        images, labels = images.to(device), labels.to(device)  # Mover los datos a la GPU/CPU\n","\n","        optimizer.zero_grad()       # Reiniciar los gradientes\n","        outputs = model(images)     # Paso hacia adelante\n","        loss = criterion(outputs, labels)  # Calcular la pérdida\n","        loss.backward()             # Paso hacia atrás (cálculo de gradientes)\n","        optimizer.step()            # Actualizar los pesos\n","\n","        running_loss += loss.item()  # Acumular la pérdida\n","    return running_loss / len(loader)  # Devolver la pérdida promedio\n","\n","# Definir la función de evaluación\n","def evaluate(model, loader, device):\n","    model.eval()  # Establecer el modelo en modo de evaluación\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():  # Deshabilitar el cálculo de gradientes para ahorrar memoria\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)  # Mover datos a la GPU/CPU\n","            outputs = model(images)  # Paso hacia adelante\n","            _, predicted = torch.max(outputs, 1)  # Obtener las predicciones (clase con mayor probabilidad)\n","            total += labels.size(0)  # Contar el número total de ejemplos\n","            correct += (predicted == labels).sum().item()  # Contar las predicciones correctas\n","    return correct / total  # Calcular la precisión\n","\n","# Bucle principal de entrenamiento\n","num_epochs = 10  # Número de épocas\n","for epoch in range(num_epochs):\n","    # Entrenar el modelo y calcular la pérdida\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    # Evaluar el modelo en el conjunto de prueba\n","    test_accuracy = evaluate(model, test_loader, device)\n","    # Imprimir los resultados de la época actual\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n","\n","# Calcular la precisión final en el conjunto de prueba\n","final_accuracy = evaluate(model, test_loader, device)\n","print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6e8ecpJmaLMk"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}